name: "roberta-base_exp"

model_savename: "roberta-base"
model_name: 'roberta-base'

max_length: 512
inference_max_length: 512
train_batch_size: 8
valid_batch_size: 8
lr: 8e-5

num_labels: 15
label_subtokens: True
output_hidden_states: True
hidden_dropout_prob: 0.1
layer_norm_eps: 1e-7
add_pooling_layer: False

n_epoch: 2 # not to exceed runtime limit
n_fold: 5
verbose_steps: 500
random_seed: 42

is_debug: False
# debug_sample: 1000
# verbose_steps: 16
# n_epoch: 1
# n_fold: 2

